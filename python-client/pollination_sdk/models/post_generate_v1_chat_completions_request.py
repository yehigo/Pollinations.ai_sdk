# coding: utf-8

"""
    pollinations.ai API

    Documentation for `gen.pollinations.ai` - the pollinations.ai API gateway.  [ðŸ“ Edit docs](https://github.com/pollinations/pollinations/edit/master/enter.pollinations.ai/src/routes/docs.ts)  ## Quick Start  Get your API key at https://enter.pollinations.ai  ### Image Generation ```bash curl 'https://gen.pollinations.ai/image/a%20cat?model=flux' \\   -H 'Authorization: Bearer YOUR_API_KEY' ```  ### Text Generation ```bash curl 'https://gen.pollinations.ai/v1/chat/completions' \\   -H 'Authorization: Bearer YOUR_API_KEY' \\   -H 'Content-Type: application/json' \\   -d '{\"model\": \"openai\", \"messages\": [{\"role\": \"user\", \"content\": \"Hello\"}]}' ```  ### Vision (Image Input) ```bash curl 'https://gen.pollinations.ai/v1/chat/completions' \\   -H 'Authorization: Bearer YOUR_API_KEY' \\   -H 'Content-Type: application/json' \\   -d '{\"model\": \"openai\", \"messages\": [{\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": \"Describe this image\"}, {\"type\": \"image_url\", \"image_url\": {\"url\": \"https://example.com/image.jpg\"}}]}]}' ```  **Gemini Tools:** `gemini`, `gemini-large` have `code_execution` enabled (can generate images/plots). `gemini-search` has `google_search` enabled. Responses may include `content_blocks` with `image_url`, `text`, or `thinking` types.  ### Simple Text Endpoint ```bash curl 'https://gen.pollinations.ai/text/hello?key=YOUR_API_KEY' ```  ### Streaming ```bash curl 'https://gen.pollinations.ai/v1/chat/completions' \\   -H 'Authorization: Bearer YOUR_API_KEY' \\   -H 'Content-Type: application/json' \\   -d '{\"model\": \"openai\", \"messages\": [{\"role\": \"user\", \"content\": \"Write a poem\"}], \"stream\": true}' \\   --no-buffer ```  ### Model Discovery **Always check available models before testing:**  - **Image models:** [/image/models](https://gen.pollinations.ai/image/models) - **Text models:** [/v1/models](https://gen.pollinations.ai/v1/models)  ## Authentication  **Two key types (both consume Pollen from your balance):** - **Publishable Keys (`pk_`):** âš ï¸ **Beta - not yet ready for production use.** For client-side apps, IP rate-limited (1 pollen per IP per hour). **Warning:** Exposing in public code will consume your Pollen if your app gets traffic. - **Secret Keys (`sk_`):** Server-side only, no rate limits. Keep secret - never expose publicly.  **Auth methods:** 1. Header: `Authorization: Bearer YOUR_API_KEY` 2. Query param: `?key=YOUR_API_KEY`  ## Account Management  Check your balance and usage:  ```bash # Check pollen balance curl 'https://gen.pollinations.ai/account/balance' \\   -H 'Authorization: Bearer YOUR_API_KEY'  # Get profile info curl 'https://gen.pollinations.ai/account/profile' \\   -H 'Authorization: Bearer YOUR_API_KEY'  # View usage history curl 'https://gen.pollinations.ai/account/usage' \\   -H 'Authorization: Bearer YOUR_API_KEY' ```

    The version of the OpenAPI document: 0.3.0
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field, StrictBool, StrictStr, field_validator
from typing import Any, ClassVar, Dict, List, Optional, Union
from typing_extensions import Annotated
from pollination_sdk.models.post_generate_v1_chat_completions_request_audio import PostGenerateV1ChatCompletionsRequestAudio
from pollination_sdk.models.post_generate_v1_chat_completions_request_function_call import PostGenerateV1ChatCompletionsRequestFunctionCall
from pollination_sdk.models.post_generate_v1_chat_completions_request_functions_inner import PostGenerateV1ChatCompletionsRequestFunctionsInner
from pollination_sdk.models.post_generate_v1_chat_completions_request_messages_inner import PostGenerateV1ChatCompletionsRequestMessagesInner
from pollination_sdk.models.post_generate_v1_chat_completions_request_response_format import PostGenerateV1ChatCompletionsRequestResponseFormat
from pollination_sdk.models.post_generate_v1_chat_completions_request_stop import PostGenerateV1ChatCompletionsRequestStop
from pollination_sdk.models.post_generate_v1_chat_completions_request_stream_options import PostGenerateV1ChatCompletionsRequestStreamOptions
from pollination_sdk.models.post_generate_v1_chat_completions_request_thinking import PostGenerateV1ChatCompletionsRequestThinking
from pollination_sdk.models.post_generate_v1_chat_completions_request_tool_choice import PostGenerateV1ChatCompletionsRequestToolChoice
from pollination_sdk.models.post_generate_v1_chat_completions_request_tools_inner import PostGenerateV1ChatCompletionsRequestToolsInner
from typing import Optional, Set
from typing_extensions import Self

class PostGenerateV1ChatCompletionsRequest(BaseModel):
    """
    PostGenerateV1ChatCompletionsRequest
    """ # noqa: E501
    messages: List[PostGenerateV1ChatCompletionsRequestMessagesInner]
    model: Optional[StrictStr] = Field(default='openai', description="AI model for text generation. See /v1/models for full list.")
    modalities: Optional[List[StrictStr]] = None
    audio: Optional[PostGenerateV1ChatCompletionsRequestAudio] = None
    frequency_penalty: Optional[Union[Annotated[float, Field(le=2, strict=True, ge=-2)], Annotated[int, Field(le=2, strict=True, ge=-2)]]] = None
    repetition_penalty: Optional[Union[Annotated[float, Field(le=2, strict=True, ge=0)], Annotated[int, Field(le=2, strict=True, ge=0)]]] = None
    logit_bias: Optional[Dict[str, Annotated[int, Field(le=9007199254740991, strict=True, ge=-9007199254740991)]]] = None
    logprobs: Optional[StrictBool] = None
    top_logprobs: Optional[Annotated[int, Field(le=20, strict=True, ge=0)]] = None
    max_tokens: Optional[Annotated[int, Field(le=9007199254740991, strict=True, ge=0)]] = None
    presence_penalty: Optional[Union[Annotated[float, Field(le=2, strict=True, ge=-2)], Annotated[int, Field(le=2, strict=True, ge=-2)]]] = None
    response_format: Optional[PostGenerateV1ChatCompletionsRequestResponseFormat] = None
    seed: Optional[Annotated[int, Field(le=9007199254740991, strict=True, ge=-1)]] = None
    stop: Optional[PostGenerateV1ChatCompletionsRequestStop] = None
    stream: Optional[StrictBool] = None
    stream_options: Optional[PostGenerateV1ChatCompletionsRequestStreamOptions] = None
    thinking: Optional[PostGenerateV1ChatCompletionsRequestThinking] = None
    reasoning_effort: Optional[StrictStr] = None
    thinking_budget: Optional[Annotated[int, Field(le=9007199254740991, strict=True, ge=0)]] = None
    temperature: Optional[Union[Annotated[float, Field(le=2, strict=True, ge=0)], Annotated[int, Field(le=2, strict=True, ge=0)]]] = None
    top_p: Optional[Union[Annotated[float, Field(le=1, strict=True, ge=0)], Annotated[int, Field(le=1, strict=True, ge=0)]]] = None
    tools: Optional[List[PostGenerateV1ChatCompletionsRequestToolsInner]] = None
    tool_choice: Optional[PostGenerateV1ChatCompletionsRequestToolChoice] = None
    parallel_tool_calls: Optional[StrictBool] = True
    user: Optional[StrictStr] = None
    function_call: Optional[PostGenerateV1ChatCompletionsRequestFunctionCall] = None
    functions: Optional[Annotated[List[PostGenerateV1ChatCompletionsRequestFunctionsInner], Field(min_length=1, max_length=128)]] = None
    __properties: ClassVar[List[str]] = ["messages", "model", "modalities", "audio", "frequency_penalty", "repetition_penalty", "logit_bias", "logprobs", "top_logprobs", "max_tokens", "presence_penalty", "response_format", "seed", "stop", "stream", "stream_options", "thinking", "reasoning_effort", "thinking_budget", "temperature", "top_p", "tools", "tool_choice", "parallel_tool_calls", "user", "function_call", "functions"]

    @field_validator('model')
    def model_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in set(['openai', 'openai-fast', 'openai-large', 'qwen-coder', 'mistral', 'openai-audio', 'gemini', 'gemini-fast', 'deepseek', 'grok', 'gemini-search', 'chickytutor', 'midijourney', 'claude-fast', 'claude', 'claude-large', 'perplexity-fast', 'perplexity-reasoning', 'kimi', 'gemini-large', 'gemini-legacy', 'nova-fast', 'glm', 'minimax', 'nomnom']):
            raise ValueError("must be one of enum values ('openai', 'openai-fast', 'openai-large', 'qwen-coder', 'mistral', 'openai-audio', 'gemini', 'gemini-fast', 'deepseek', 'grok', 'gemini-search', 'chickytutor', 'midijourney', 'claude-fast', 'claude', 'claude-large', 'perplexity-fast', 'perplexity-reasoning', 'kimi', 'gemini-large', 'gemini-legacy', 'nova-fast', 'glm', 'minimax', 'nomnom')")
        return value

    @field_validator('modalities')
    def modalities_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        for i in value:
            if i not in set(['text', 'audio']):
                raise ValueError("each list item must be one of ('text', 'audio')")
        return value

    @field_validator('reasoning_effort')
    def reasoning_effort_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in set(['none', 'minimal', 'low', 'medium', 'high', 'xhigh']):
            raise ValueError("must be one of enum values ('none', 'minimal', 'low', 'medium', 'high', 'xhigh')")
        return value

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of PostGenerateV1ChatCompletionsRequest from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of each item in messages (list)
        _items = []
        if self.messages:
            for _item_messages in self.messages:
                if _item_messages:
                    _items.append(_item_messages.to_dict())
            _dict['messages'] = _items
        # override the default output from pydantic by calling `to_dict()` of audio
        if self.audio:
            _dict['audio'] = self.audio.to_dict()
        # override the default output from pydantic by calling `to_dict()` of response_format
        if self.response_format:
            _dict['response_format'] = self.response_format.to_dict()
        # override the default output from pydantic by calling `to_dict()` of stop
        if self.stop:
            _dict['stop'] = self.stop.to_dict()
        # override the default output from pydantic by calling `to_dict()` of stream_options
        if self.stream_options:
            _dict['stream_options'] = self.stream_options.to_dict()
        # override the default output from pydantic by calling `to_dict()` of thinking
        if self.thinking:
            _dict['thinking'] = self.thinking.to_dict()
        # override the default output from pydantic by calling `to_dict()` of each item in tools (list)
        _items = []
        if self.tools:
            for _item_tools in self.tools:
                if _item_tools:
                    _items.append(_item_tools.to_dict())
            _dict['tools'] = _items
        # override the default output from pydantic by calling `to_dict()` of tool_choice
        if self.tool_choice:
            _dict['tool_choice'] = self.tool_choice.to_dict()
        # override the default output from pydantic by calling `to_dict()` of function_call
        if self.function_call:
            _dict['function_call'] = self.function_call.to_dict()
        # override the default output from pydantic by calling `to_dict()` of each item in functions (list)
        _items = []
        if self.functions:
            for _item_functions in self.functions:
                if _item_functions:
                    _items.append(_item_functions.to_dict())
            _dict['functions'] = _items
        # set to None if frequency_penalty (nullable) is None
        # and model_fields_set contains the field
        if self.frequency_penalty is None and "frequency_penalty" in self.model_fields_set:
            _dict['frequency_penalty'] = None

        # set to None if repetition_penalty (nullable) is None
        # and model_fields_set contains the field
        if self.repetition_penalty is None and "repetition_penalty" in self.model_fields_set:
            _dict['repetition_penalty'] = None

        # set to None if logit_bias (nullable) is None
        # and model_fields_set contains the field
        if self.logit_bias is None and "logit_bias" in self.model_fields_set:
            _dict['logit_bias'] = None

        # set to None if logprobs (nullable) is None
        # and model_fields_set contains the field
        if self.logprobs is None and "logprobs" in self.model_fields_set:
            _dict['logprobs'] = None

        # set to None if top_logprobs (nullable) is None
        # and model_fields_set contains the field
        if self.top_logprobs is None and "top_logprobs" in self.model_fields_set:
            _dict['top_logprobs'] = None

        # set to None if max_tokens (nullable) is None
        # and model_fields_set contains the field
        if self.max_tokens is None and "max_tokens" in self.model_fields_set:
            _dict['max_tokens'] = None

        # set to None if presence_penalty (nullable) is None
        # and model_fields_set contains the field
        if self.presence_penalty is None and "presence_penalty" in self.model_fields_set:
            _dict['presence_penalty'] = None

        # set to None if seed (nullable) is None
        # and model_fields_set contains the field
        if self.seed is None and "seed" in self.model_fields_set:
            _dict['seed'] = None

        # set to None if stream (nullable) is None
        # and model_fields_set contains the field
        if self.stream is None and "stream" in self.model_fields_set:
            _dict['stream'] = None

        # set to None if stream_options (nullable) is None
        # and model_fields_set contains the field
        if self.stream_options is None and "stream_options" in self.model_fields_set:
            _dict['stream_options'] = None

        # set to None if thinking (nullable) is None
        # and model_fields_set contains the field
        if self.thinking is None and "thinking" in self.model_fields_set:
            _dict['thinking'] = None

        # set to None if temperature (nullable) is None
        # and model_fields_set contains the field
        if self.temperature is None and "temperature" in self.model_fields_set:
            _dict['temperature'] = None

        # set to None if top_p (nullable) is None
        # and model_fields_set contains the field
        if self.top_p is None and "top_p" in self.model_fields_set:
            _dict['top_p'] = None

        # set to None if user (nullable) is None
        # and model_fields_set contains the field
        if self.user is None and "user" in self.model_fields_set:
            _dict['user'] = None

        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of PostGenerateV1ChatCompletionsRequest from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "messages": [PostGenerateV1ChatCompletionsRequestMessagesInner.from_dict(_item) for _item in obj["messages"]] if obj.get("messages") is not None else None,
            "model": obj.get("model") if obj.get("model") is not None else 'openai',
            "modalities": obj.get("modalities"),
            "audio": PostGenerateV1ChatCompletionsRequestAudio.from_dict(obj["audio"]) if obj.get("audio") is not None else None,
            "frequency_penalty": obj.get("frequency_penalty"),
            "repetition_penalty": obj.get("repetition_penalty"),
            "logit_bias": obj.get("logit_bias"),
            "logprobs": obj.get("logprobs"),
            "top_logprobs": obj.get("top_logprobs"),
            "max_tokens": obj.get("max_tokens"),
            "presence_penalty": obj.get("presence_penalty"),
            "response_format": PostGenerateV1ChatCompletionsRequestResponseFormat.from_dict(obj["response_format"]) if obj.get("response_format") is not None else None,
            "seed": obj.get("seed"),
            "stop": PostGenerateV1ChatCompletionsRequestStop.from_dict(obj["stop"]) if obj.get("stop") is not None else None,
            "stream": obj.get("stream"),
            "stream_options": PostGenerateV1ChatCompletionsRequestStreamOptions.from_dict(obj["stream_options"]) if obj.get("stream_options") is not None else None,
            "thinking": PostGenerateV1ChatCompletionsRequestThinking.from_dict(obj["thinking"]) if obj.get("thinking") is not None else None,
            "reasoning_effort": obj.get("reasoning_effort"),
            "thinking_budget": obj.get("thinking_budget"),
            "temperature": obj.get("temperature"),
            "top_p": obj.get("top_p"),
            "tools": [PostGenerateV1ChatCompletionsRequestToolsInner.from_dict(_item) for _item in obj["tools"]] if obj.get("tools") is not None else None,
            "tool_choice": PostGenerateV1ChatCompletionsRequestToolChoice.from_dict(obj["tool_choice"]) if obj.get("tool_choice") is not None else None,
            "parallel_tool_calls": obj.get("parallel_tool_calls") if obj.get("parallel_tool_calls") is not None else True,
            "user": obj.get("user"),
            "function_call": PostGenerateV1ChatCompletionsRequestFunctionCall.from_dict(obj["function_call"]) if obj.get("function_call") is not None else None,
            "functions": [PostGenerateV1ChatCompletionsRequestFunctionsInner.from_dict(_item) for _item in obj["functions"]] if obj.get("functions") is not None else None
        })
        return _obj


